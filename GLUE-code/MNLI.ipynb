{"cells":[{"cell_type":"markdown","metadata":{"id":"HO_fxsG8SaPG"},"source":["# MNLI"]},{"cell_type":"markdown","source":["## Preparing the Environment"],"metadata":{"id":"WigRB-Iipqfg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"SXsIRM-X-Mfj"},"outputs":[],"source":["#Google Colab - Drive Mounting\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TJXN1jh19ImI"},"outputs":[],"source":["#Install missing library keras-nlp\n","!pip install -q keras-nlp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g77CCOKH-CTz"},"outputs":[],"source":["#Import the libraries\n","import tensorflow as tf\n","import keras_nlp\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import numpy as np\n","import os\n","import re\n","import string\n","import random\n","import pandas as pd\n","import csv"]},{"cell_type":"markdown","source":["## Data Preprocessing and Parameters Initialization"],"metadata":{"id":"IZ0RPOZKp6Pa"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"E57cipHC-_I3"},"outputs":[],"source":["#Finetuning Parameters\n","FINETUNING_LEARNING_RATE = 5e-5\n","FINETUNING_EPOCHS = 3\n","FINETUNING_BATCH_SIZE = 32\n","SEQ_LENGTH = 128"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JAK-npjI-hwl"},"outputs":[],"source":["# Download of the vocabulary from BERT: Bert-uncased\n","vocab_file = keras.utils.get_file(\n","    origin=\"https://storage.googleapis.com/tensorflow/keras-nlp/examples/bert/bert_vocab_uncased.txt\",\n",")\n","#Initialization of the Word Tokenizer, with a given vocabulary and a sequence length\n","tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n","    vocabulary=vocab_file, sequence_length=SEQ_LENGTH,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SvBLRkZNY2TN"},"outputs":[],"source":["#Definition of the classes dictionary\n","CLASSES = {\n","    'neutral': 0,\n","    'entailment': 1,\n","    'contradiction': 2,\n","}\n","\n","\n","current_path = \"path_to_MNLI/MNLI\"\n","train_path = os.path.join(current_path, 'train.tsv')\n","dev_matched_path = os.path.join(current_path, 'dev_matched.tsv')\n","dev_mismatched_path = os.path.join(current_path, 'dev_mismatched.tsv')"]},{"cell_type":"markdown","metadata":{"id":"2Hiq1MLcFTD_"},"source":["Reference https://github.com/CyberZHG/keras-xlnet/blob/master/demo/GLUE/MNLI/mnli.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3h0EzxWy9TvG"},"outputs":[],"source":["# Definition of the Class Data using Keras Sequence format\n","class DataSequence(keras.utils.Sequence):\n","    '''\n","    Organize the data into: encoded text/ label \n","    Overwrite the Keras.Utils.Sequence Class\n","    '''\n","    def __init__(self, x, y):\n","        self.x = x\n","        self.y = y\n","\n","    def __len__(self):\n","        return (len(self.y) + FINETUNING_BATCH_SIZE - 1) // FINETUNING_BATCH_SIZE\n","\n","    def __getitem__(self, index):\n","        s = slice(index * FINETUNING_BATCH_SIZE, (index + 1) * FINETUNING_BATCH_SIZE)\n","        return [item[s] for item in self.x], self.y[s]\n","\n","\n","def generate_sequence(path):\n","    '''\n","    Given a file path, read the file and organize the data from the file\n","    Return Keras.utils.Sequence object ready to use for training, with the format: tokens/classes\n","    '''\n","    tokens, classes = [], []\n","    df = pd.read_csv(path, sep='\\t', error_bad_lines=False)\n","    for _, row in df.iterrows():\n","        text_a, text_b, cls = row['sentence1'], row['sentence2'], row['gold_label']\n","        if not isinstance(text_a, str) or not isinstance(text_b, str) or cls not in CLASSES:\n","            continue\n","        text = (text_a)+ '[SEP]' + (text_b) + '[SEP]'\n","        encoded = tokenizer(text)\n","        tokens.append(encoded)\n","        classes.append(CLASSES[cls])\n","    tokens, classes = np.array(tokens), np.array(classes)\n","    return DataSequence([tokens], classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cb3W7axnL2bo"},"outputs":[],"source":["#Load the training data\n","train_data = generate_sequence(train_path)\n","dev_matched_data = generate_sequence(dev_matched_path)\n","dev_mismatched_data = generate_sequence(dev_mismatched_path)"]},{"cell_type":"markdown","source":["## Load the model and change the head"],"metadata":{"id":"_5iBrwXAqgIw"}},{"cell_type":"code","source":["# Load the pretrained model and display its structure\n","model = keras.models.load_model('path_to_the_pretrained_model',compile=False)\n","model.summary()"],"metadata":{"id":"g4RgpY4KqlbA"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GC7XDvzA_OhO"},"outputs":[],"source":["# The model's head is modified for classification\n","\n","inputs = keras.Input(shape=(SEQ_LENGTH,), dtype=tf.int32)\n","encoded_tokens = model(inputs)\n","#HEAD FROM https://keras.io/examples/nlp/text_classification_with_transformer/\n","x = keras.layers.GlobalAveragePooling1D()(encoded_tokens)\n","x = keras.layers.Dropout(0.1)(x)\n","x = keras.layers.Dense(768, activation=\"tanh\")(x)\n","x = keras.layers.Dropout(0.1)(x)\n","outputs = keras.layers.Dense(3, activation=\"softmax\")(x)\n","\n","\n","finetuning_model = keras.models.Model(inputs=inputs, outputs=outputs)\n","finetuning_model.summary()"]},{"cell_type":"markdown","source":["## Model Training"],"metadata":{"id":"dCpCRK4nq4dz"}},{"cell_type":"code","source":["#Create tensorboard callback\n","logdir = \"path_to_save_execution_information\" #+ datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n","\n","#Compile model \n","finetuning_model.compile(\n","    optimizer=keras.optimizers.Adam(lr=3e-5),\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['sparse_categorical_accuracy'],\n",")"],"metadata":{"id":"8IBnbdr0qzeX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Model training\n","finetuning_model.fit_generator(\n","    generator=train_data,\n","    validation_data=dev_matched_data,\n","    epochs=FINETUNING_EPOCHS,\n","    callbacks=[tensorboard_callback],\n",")"],"metadata":{"id":"38JwRJqrq_X_"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K8e708IqcTUk"},"outputs":[],"source":["# Add Tokenization layer to the model\n","inputs = keras.Input(shape=(), dtype=tf.string)\n","tokens = tokenizer(inputs)\n","outputs = finetuning_model(tokens)\n","\n","#Save model\n","final_model = keras.Model(inputs, outputs)\n","final_model.save(\"path_to_save_model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4xDvglkMc1p8"},"outputs":[],"source":["#Restore model\n","restored_model = keras.models.load_model(\"path_to_save_model\", compile=False)"]},{"cell_type":"markdown","source":["## Testing"],"metadata":{"id":"i_q3kVvNrFdF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xJnIBpxHdLnS"},"outputs":[],"source":["current_path = \"path_to_MNLI/MNLI\"\n","test_match_path = os.path.join(current_path, 'test_matched.tsv')\n","test_mismatched_path = os.path.join(current_path, 'test_mismatched.tsv')\n","\n","\n","def generate_test(path):\n","    '''\n","    Given a file path, read the file and preprocess the data\n","    Return a numpy array of the encoded test sentences\n","    '''\n","    tokens, classes = [], []\n","    df = pd.read_csv(path, sep='\\t',quoting=csv.QUOTE_NONE)\n","    for _, row in df.iterrows():\n","        text_a, text_b = row['sentence1'], row['sentence2']\n","        if not isinstance(text_a, str) or not isinstance(text_b, str):\n","            text_a = str(text_a)\n","            text_b = str(text_b)\n","        text = str(text_a)+ '[SEP]' + str(text_b) + '[SEP]'\n","        encoded = (text)\n","        tokens.append(encoded)\n","    tokens = (tokens)\n","    return tokens \n","\n","#Load the test data\n","test_m = generate_test(test_match_path)\n","test_mm = generate_test(test_mismatched_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"91x2jKSuyOID"},"outputs":[],"source":["#Generate predictions for matched test data and mismatched test data \n","pred_m = restored_model.predict(test_m, batch_size=128).argmax(axis=-1)\n","pred_mm = restored_model.predict(test_mm, batch_size=128).argmax(axis=-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sxl2HwDPex9K"},"outputs":[],"source":["#Print the number of results\n","print(len(pred_m))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zo7G4dtQyRwr"},"outputs":[],"source":["#Format results into dataframe, ready to be uploaded on gluebenchmark.com\n","\n","REV_CLASSES = {\n","    0: 'neutral',\n","    1: 'entailment',\n","    2: 'contradiction',\n","}\n","\n","results_m = []\n","results_mm = []\n","\n","for p in pred_m:\n","  results_m.append(REV_CLASSES[p])\n","\n","for p in pred_mm:\n","  results_mm.append(REV_CLASSES[p])\n","\n","df_m = pd.DataFrame(results_m)\n","df_mm = pd.DataFrame(results_mm)\n","\n","df_m.to_csv(\"MNLI-m.tsv\",sep='\\t', encoding='utf-8')\n","df_mm.to_csv(\"MNLI-mm.tsv\",sep='\\t', encoding='utf-8')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hdh8WEoVyTVM"},"outputs":[],"source":["#Load Tensorboard\n","%reload_ext tensorboard\n","%tensorboard --logdir=\"path_to_save_execution_information\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YX6224AfreTW"},"outputs":[],"source":["#Code to automatically stop the run time for Google Colab\n","import time\n","time.sleep(60)\n","from google.colab import runtime\n","runtime.unassign()"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}