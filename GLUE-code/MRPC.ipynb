{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOZdBT9QSdfAv7mrQf8n6jR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# MRPC"],"metadata":{"id":"I9Hd13gH3-_S"}},{"cell_type":"markdown","source":["## Preparing the Environment"],"metadata":{"id":"4dh9-cmXySls"}},{"cell_type":"code","source":["#Google Colab - Drive Mounting\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"id":"8Z40uaB0HLQF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Install missing library keras-nlp\n","!pip install -q keras-nlp"],"metadata":{"id":"JglDsvZ1kbjr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Import the libraries\n","import os\n","import keras_nlp\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import urllib.request\n","import pandas as pd"],"metadata":{"id":"xd-7tzpvn5mJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Preprocessing and Parameters Initialization"],"metadata":{"id":"46MvMxLZycky"}},{"cell_type":"code","source":["#Finetuning Parameters\n","FINETUNING_BATCH_SIZE = 32\n","SEQ_LENGTH = 128\n","FINETUNING_LEARNING_RATE = 5e-5\n","FINETUNING_EPOCHS = 3"],"metadata":{"id":"4mZ8X9mToBjI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Uncomment three last lines for downloading mrpc data: given data is in 'msr' format and is difficult to use\n","\n","MRPC_TRAIN = 'https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt'\n","MRPC_TEST = 'https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_test.txt'\n","MRPC_DEV = 'https://raw.githubusercontent.com/MegEngine/Models/master/official/nlp/bert/glue_data/MRPC/dev_ids.tsv'\n","\n","mrpc_train_file ='path_to_mrpc/msr_paraphrase_train.txt'\n","mrpc_test_file ='path_to_mrpc/msr_paraphrase_test.txt'\n","mrpc_dev_file ='path_to_mrpc/msr_dev_ids.txt'\n","\n","# urllib.request.urlretrieve(MRPC_TRAIN, mrpc_train_file)\n","# urllib.request.urlretrieve(MRPC_TEST, mrpc_test_file)\n","# urllib.request.urlretrieve(MRPC_DEV, mrpc_dev_file)"],"metadata":{"id":"A2WL7eEmpoAw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download of the vocabulary from BERT: Bert-uncased\n","vocab_file = keras.utils.get_file(\n","    origin=\"https://storage.googleapis.com/tensorflow/keras-nlp/examples/bert/bert_vocab_uncased.txt\",\n",")\n","#Initialization of the Word Tokenizer, with a given vocabulary and a sequence length\n","tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n","    vocabulary=vocab_file, sequence_length=SEQ_LENGTH,\n",")"],"metadata":{"id":"gtC3cCONtvoV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Definition of the Class Data using Keras Sequence format\n","class DataSequence(keras.utils.Sequence):\n","    '''\n","    Organize the data into: encoded text/ label \n","    Overwrite the Keras.Utils.Sequence Class\n","    '''\n","\n","    def __init__(self, x, y):\n","        self.x = x\n","        self.y = y\n","\n","    def __len__(self):\n","        return (len(self.y) + FINETUNING_BATCH_SIZE - 1) // FINETUNING_BATCH_SIZE\n","\n","    def __getitem__(self, index):\n","        s = slice(index * FINETUNING_BATCH_SIZE, (index + 1) * FINETUNING_BATCH_SIZE)\n","        return [item[s] for item in self.x], self.y[s]\n","\n","def generate_sequence(path, dev_ids=None, select_dev=False):\n","    '''\n","    Given a file path, read the file and organize the data from the file\n","    Return Keras.utils.Sequence object ready to use for training, with the format: tokens/classes\n","    '''\n","    tokens, classes = [], []\n","    with open(path) as reader:\n","        reader.readline()\n","        for line in reader:\n","            line = line.strip()\n","            parts = line.split('\\t')\n","            ids = (parts[1], parts[2])\n","            if dev_ids is not None:\n","                if select_dev:\n","                    if ids not in dev_ids:\n","                        continue\n","                else:\n","                    if ids in dev_ids:\n","                        continue\n","            text = (parts[3]) + '[SEP]' + (parts[4]) + '[SEP]'\n","            encoded = tokenizer(text)\n","            tokens.append(encoded)\n","            classes.append(int(parts[0], 10))\n","    tokens, classes = np.array(tokens), np.array(classes)\n","    return DataSequence([tokens], classes)"],"metadata":{"id":"Rv75BdQmq7Y0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#For dev set\n","with open(mrpc_dev_file) as dev_reader:\n","    dev_ids = set([tuple(line.strip().split('\\t')) for line in dev_reader])"],"metadata":{"id":"P8PHlKZRtaBa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Load the training data\n","train_seq = generate_sequence(mrpc_train_file, dev_ids=dev_ids, select_dev=False)\n","dev_seq = generate_sequence(mrpc_train_file, dev_ids=dev_ids, select_dev=True)\n","test_seq = generate_sequence(mrpc_test_file)"],"metadata":{"id":"2_301r5KtOTu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load the model and change the head"],"metadata":{"id":"rz4Fx-wIy5QM"}},{"cell_type":"code","source":["# Load the pretrained model and display its structure\n","model = keras.models.load_model('path_to_the_pretrained_model',compile=False)\n","model.summary()"],"metadata":{"id":"i8eDvVfjy0oZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The model's head is modified for classification\n","\n","inputs = keras.Input(shape=(SEQ_LENGTH,), dtype=tf.int32)\n","encoded_tokens = model(inputs)\n","#HEAD FROM https://keras.io/examples/nlp/text_classification_with_transformer/\n","x = keras.layers.GlobalAveragePooling1D()(encoded_tokens)\n","x = keras.layers.Dropout(0.1)(x)\n","x = keras.layers.Dense(768, activation=\"tanh\")(x)\n","x = keras.layers.Dropout(0.1)(x)\n","outputs = keras.layers.Dense(2, activation=\"softmax\")(x)\n","\n","finetuning_model = keras.models.Model(inputs=inputs, outputs=outputs)\n","finetuning_model.summary()"],"metadata":{"id":"Jw_SwJfPvYTN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model Training"],"metadata":{"id":"dsY_i12szFgW"}},{"cell_type":"code","source":["#Create tensorboard callback\n","logdir = \"path_to_save_execution_information\" #+ datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n","\n","#Compile model \n","finetuning_model.compile(\n","    optimizer=keras.optimizers.Adam(lr=3e-5),\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['sparse_categorical_accuracy'],\n",")"],"metadata":{"id":"aUsM3z1putCb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Model training\n","finetuning_model.fit_generator(\n","    generator=train_seq,\n","    validation_data=dev_seq,\n","    epochs=FINETUNING_EPOCHS,\n","    callbacks=[tensorboard_callback],\n",")"],"metadata":{"id":"tDcKNBZTzPRr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Add Tokenization layer to the model\n","inputs = keras.Input(shape=(), dtype=tf.string)\n","tokens = tokenizer(inputs)\n","outputs = finetuning_model(tokens)\n","\n","#Save model\n","final_model = keras.Model(inputs, outputs)\n","final_model.save(\"path_to_save_model\")"],"metadata":{"id":"kpoGHe907AfW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Restore model\n","restored_model = keras.models.load_model(\"path_to_save_model\", compile=False)"],"metadata":{"id":"3tNC8Tq57JnN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Testing"],"metadata":{"id":"zSq86zRCzkbe"}},{"cell_type":"code","source":["def generate_test(path, dev_ids=None, select_dev=False):\n","    '''\n","    Given a file path, read the file and preprocess the data\n","    Return a numpy array of the test sentences\n","    '''\n","    tokens, classes = [], []\n","    with open(path) as reader:\n","        reader.readline()\n","        for line in reader:\n","            line = line.strip()\n","            parts = line.split('\\t')\n","            ids = (parts[1], parts[2])\n","            if dev_ids is not None:\n","                if select_dev:\n","                    if ids not in dev_ids:\n","                        continue\n","                else:\n","                    if ids in dev_ids:\n","                        continue\n","            text = (parts[3]) + '[SEP]' + (parts[4]) + '[SEP]'\n","            encoded = (text)\n","            tokens.append(encoded)\n","            classes.append(int(parts[0], 10))\n","    tokens, classes = np.array(tokens), np.array(classes)\n","    return DataSequence([tokens], classes)\n","\n","#Load the test data\n","test_seq = generate_test(mrpc_test_file)"],"metadata":{"id":"lRTLunpe-B0a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Generate predictions\n","results = restored_model.predict(test_seq, verbose=True).argmax(axis=-1)"],"metadata":{"id":"XB4Ymqe469H7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Format results into dataframe, ready to be uploaded on gluebenchmark.com\n","df = pd.DataFrame(results)\n","\n","df.to_csv(\"MRPC.tsv\",sep='\\t', encoding='utf-8')"],"metadata":{"id":"EbYtOfxB7YJ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Load Tensorboard\n","%reload_ext tensorboard\n","%tensorboard --logdir=\"path_to_save_execution_information\""],"metadata":{"id":"ie8ubdmQv-44"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YX6224AfreTW"},"outputs":[],"source":["#Code to automatically stop the run time for Google Colab\n","import time\n","time.sleep(60)\n","from google.colab import runtime\n","runtime.unassign()"]}]}