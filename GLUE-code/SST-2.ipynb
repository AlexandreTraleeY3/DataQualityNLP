{"cells":[{"cell_type":"markdown","metadata":{"id":"mOmyT8MMw0CI"},"source":["# SST-2"]},{"cell_type":"markdown","source":["## Preparing the Environment"],"metadata":{"id":"5MJqbYIN21By"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"uZHx5ril3TUa"},"outputs":[],"source":["#Google Colab - Drive Mounting\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jUSbQLAa3Lxe"},"outputs":[],"source":["#Install missing library keras-nlp\n","!pip install -q keras-nlp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dSqsk53m3Umx"},"outputs":[],"source":["#Import the libraries\n","import os\n","import keras_nlp\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"markdown","source":["## Data Preprocessing and Parameters Initialization"],"metadata":{"id":"M0xEn97e3Tl1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4bre26-W3XZi"},"outputs":[],"source":["#Finetuning Parameters\n","FINETUNING_LEARNING_RATE = 5e-5\n","FINETUNING_EPOCHS = 3\n","FINETUNING_BATCH_SIZE = 32\n","SEQ_LENGTH = 128"]},{"cell_type":"code","source":["# Download of the vocabulary from BERT: Bert-uncased\n","vocab_file = keras.utils.get_file(\n","    origin=\"https://storage.googleapis.com/tensorflow/keras-nlp/examples/bert/bert_vocab_uncased.txt\",\n",")\n","#Initialization of the Word Tokenizer, with a given vocabulary and a sequence length\n","tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n","    vocabulary=vocab_file, sequence_length=SEQ_LENGTH,\n",")"],"metadata":{"id":"zf5g9u1Z3hPw"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ItYGf1KU3ZBt"},"outputs":[],"source":["# Download SST-2 data\n","keras.utils.get_file(\n","    origin=\"https://dl.fbaipublicfiles.com/glue/data/SST-2.zip\", extract=True,\n",")\n","sst_dir = os.path.expanduser(\"~/.keras/datasets/SST-2/\")\n","\n","# Load SST-2.\n","sst_train_ds = tf.data.experimental.CsvDataset(\n","    sst_dir + \"train.tsv\", [tf.string, tf.int32], header=True, field_delim=\"\\t\"\n",").batch(FINETUNING_BATCH_SIZE)\n","sst_val_ds = tf.data.experimental.CsvDataset(\n","    sst_dir + \"dev.tsv\", [tf.string, tf.int32], header=True, field_delim=\"\\t\"\n",").batch(FINETUNING_BATCH_SIZE)\n","sst_test_ds = tf.data.experimental.CsvDataset(\n","    sst_dir + \"test.tsv\", [tf.int32,tf.string], header=True, field_delim=\"\\t\"\n",").batch(FINETUNING_BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"20C2Zv4r4Ttv"},"outputs":[],"source":["def preprocess(sentence, label):\n","    \"\"\"\n","    Given a sentence and a label, return tokenized sentence and the label associated\n","    \"\"\"\n","    return tokenizer(sentence), label\n","\n","\n","#Map the Data to the preprocess function\n","finetune_ds = sst_train_ds.map(\n","    preprocess, num_parallel_calls=tf.data.AUTOTUNE\n",").prefetch(tf.data.AUTOTUNE)\n","finetune_val_ds = sst_val_ds.map(\n","    preprocess, num_parallel_calls=tf.data.AUTOTUNE\n",").prefetch(tf.data.AUTOTUNE)"]},{"cell_type":"code","source":["# Load the pretrained model and display its structure\n","model = keras.models.load_model('path_to_the_pretrained_model',compile=False)\n","model.summary()"],"metadata":{"id":"JtZU8Nib4HNP"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x3HY-Dyc4YQV"},"outputs":[],"source":["# The model's head is modified for classification\n","inputs = keras.Input(shape=(SEQ_LENGTH,), dtype=tf.int32)\n","encoded_tokens = model(inputs)\n","#HEAD FROM https://keras.io/examples/nlp/text_classification_with_transformer/\n","x = keras.layers.GlobalAveragePooling1D()(encoded_tokens)\n","x = keras.layers.Dropout(0.1)(x)\n","x = keras.layers.Dense(20, activation=\"relu\")(x)\n","x = keras.layers.Dropout(0.1)(x)\n","outputs = keras.layers.Dense(2, activation=\"softmax\")(x)\n","\n","finetuning_model = keras.Model(inputs, outputs)\n","finetuning_model.summary()"]},{"cell_type":"markdown","source":["## Model Training"],"metadata":{"id":"iwXs4Tnv4yJx"}},{"cell_type":"code","source":["# Create tensorboard callback\n","logdir = \"path_to_save_execution_information\" #+ datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n","\n","finetuning_model.compile(\n","    loss=\"sparse_categorical_crossentropy\",\n","    optimizer=keras.optimizers.Adam(learning_rate=FINETUNING_LEARNING_RATE),\n","    metrics=[\"sparse_categorical_accuracy\"],\n",")"],"metadata":{"id":"Kv8oskd84lBq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Model training\n","finetuning_model.fit(\n","    finetune_ds, validation_data=finetune_val_ds, epochs=FINETUNING_EPOCHS,callbacks=[tensorboard_callback]\n",")"],"metadata":{"id":"qWyvmy674-vF"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zv7XR9vl4rch"},"outputs":[],"source":["# Add Tokenization layer to the model\n","inputs = keras.Input(shape=(), dtype=tf.string)\n","tokens = tokenizer(inputs)\n","outputs = finetuning_model(tokens)\n","final_model = keras.Model(inputs, outputs)\n","final_model.save(\"path_to_save_model\")"]},{"cell_type":"code","source":["# Restore the saved model\n","restored_model = keras.models.load_model(\"path_to_save_model\", compile=False)"],"metadata":{"id":"dAZ2_1TR5G6C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oYh5SuWrRenn"},"source":["# Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GhlDgGyvRb--"},"outputs":[],"source":["def preprocess(index, sentence):\n","  \"\"\"\n","  Given a sentence, returns the tokenize sentence\n","  \"\"\"\n","  return tokenizer(sentence)\n","\n","#Load test and generate data\n","test_ds = sst_test_ds.map(\n","    preprocess, num_parallel_calls=tf.data.AUTOTUNE\n",").prefetch(tf.data.AUTOTUNE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xOE8cYU9RhiX"},"outputs":[],"source":["# Generate predictions\n","pred = finetuning_model.predict(test_ds, batch_size=128, verbose=True).argmax(axis=-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DaBItmKK_i_0"},"outputs":[],"source":["# Format predictions to labels\n","result = np.where(pred > 0.5, 1, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KGp1WdJWRlY1"},"outputs":[],"source":["#Format results into dataframe, ready to be uploaded on gluebenchmark.com\n","df = pd.DataFrame(result)\n","df.to_csv(\"SST-2.tsv\",sep='\\t', encoding='utf-8')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"POMFUT30qFOR"},"outputs":[],"source":["#Load Tensorboard\n","%reload_ext tensorboard\n","%tensorboard --logdir=\"path_to_save_execution_information\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YX6224AfreTW"},"outputs":[],"source":["#Code to automatically stop the run time for Google Colab\n","import time\n","time.sleep(60)\n","from google.colab import runtime\n","runtime.unassign()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}